{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f9fe6ab",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "\n",
    "다양한 머신러닝 기법 중에 특히 좋은 성능을 보이는 기법으로 앙상블이 있다. 앙상블은 단일 모델이 아닌 여러 모델을 활용하여 더 나은 결과를 도출하는 기법이다.\n",
    "\n",
    "앙상블 기법은 크게 Bagging 과 Boosting 이 있는데, 본문에서는 Boosting 에 대해 알아볼 것이다.\n",
    "\n",
    "Bagging 에서 여러 모델의 투표를 통해 결과를 예측한다면, Boosting 은 하나의 모델 $A$가 예측했을 때의 오차를 다시 다른 모델 $B$를 예측 하고, 이를 반복 하는 기법이다.\n",
    "\n",
    "이 때 $A$ 와 $B$ 를 weak learner 라고 한다. 즉 weak learner 여러개를 더하여 strong learner 를 만드는 것이 Boosting 이라 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b25e0a",
   "metadata": {},
   "source": [
    "## Boosting 의 종류\n",
    "\n",
    "대표적인 Boosting 알고리즘으로 Adaboost, Gradient Boosting, XGBoost, LightGBM 등이 있다. Adaboost 가 1997년에 개발된 최초의 부스팅 알고리즘이다. Adaboost 는 이전 weak learner 가 틀렸던 샘플에 대해 높은 가중치를 주어 오차를 줄이는 기법이고, Gradient Boost 는 이전 weak learner 의 오차를 데이터로 삼아 새로운 weak learner 에 적합 시킨 후 합하는 방식이다.\n",
    "\n",
    "부스팅에서는 일반적으로 의사결정나무(DT)를 weak learner 로 사용한다. 따라서 먼저 DT를 구현 하고 실제 데이터로 확인 해보자.\n",
    "\n",
    "주의해야 할 점은 DT를 구현할 때 Boosting 에 적용 시킬 수 있게 하기 위하여 가중치가 적용 될 수 있게끔 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "b12fe7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.datasets import load_iris, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "05caa15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DT:\n",
    "    def __init__(self, max_depth=2, weights=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.weights = weights\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.target_size = np.max(y) + 1\n",
    "        self.tree = self._make_tree(X, y, self.max_depth, self.weights)\n",
    "    \n",
    "    def _gini(self, y, weights):\n",
    "        unique, cnt = np.unique(y, return_counts=True)\n",
    "        if weights is not None:\n",
    "            cnt = np.array([np.sum(weights[np.where(y==i)[0]]) for i in unique])\n",
    "        cnt = cnt / cnt.sum()\n",
    "        return 1 - np.sum(cnt * cnt)\n",
    "    \n",
    "    def _make_tree(self, X, y, depth, weights):\n",
    "        # leaf node\n",
    "        if depth == 0 or len(np.unique(y)) == 1:\n",
    "            prob = np.zeros(self.target_size)\n",
    "            unique, cnt = np.unique(y, return_counts=True)\n",
    "            if self.weights is not None:\n",
    "                cnt = np.array([weights[np.where(y==i)[0]].sum() for i in unique])\n",
    "            prob[unique] = cnt / cnt.sum()\n",
    "            return { \"leaf\": True, \"prob\": prob, \"size\": len(y) }\n",
    "\n",
    "        min_gini = 1\n",
    "        min_col = 0\n",
    "        split = None\n",
    "\n",
    "        for i, col in enumerate(X.T):\n",
    "            u = np.sort(np.unique(col))\n",
    "            u = (u[1:] + u[:-1]) / 2\n",
    "\n",
    "            for val in u:\n",
    "                lt, rt = np.where(col <= val), np.where(col > val)\n",
    "                y_lt, y_rt = y[lt], y[rt]\n",
    "                if weights is None:\n",
    "                    cur_gini = (len(y_lt)*self._gini(y_lt, None) + len(y_rt)*self._gini(y_rt, None)) / (len(y))\n",
    "                else:\n",
    "                    w_lt, w_rt = weights[lt], weights[rt]\n",
    "                    cur_gini = (w_lt.sum()*self._gini(y_lt, w_lt) + w_rt.sum()*self._gini(y_rt, w_rt)) / weights.sum()\n",
    "                    \n",
    "                if cur_gini < min_gini:\n",
    "                    min_gini, min_col, split = cur_gini, i, val\n",
    "\n",
    "        lt = np.where(X[:, min_col] <= split)[0]\n",
    "        rt = np.where(X[:, min_col] > split)[0]\n",
    "        return {\n",
    "            \"split\": (min_col, split),\n",
    "            \"lt\": self._make_tree(X[lt, :], y[lt], depth-1, weights[lt] if weights is not None else None),\n",
    "            \"rt\": self._make_tree(X[rt, :], y[rt], depth-1, weights[rt] if weights is not None else None),\n",
    "            \"leaf\": False,\n",
    "            \"size\": len(y)\n",
    "        }\n",
    "    \n",
    "    def _predict_one(self, x):\n",
    "        cur = self.tree\n",
    "        while cur[\"leaf\"] == False:\n",
    "            col, split = cur[\"split\"]\n",
    "            cur = cur[\"lt\"] if x[col] <= split else cur[\"rt\"]\n",
    "        return cur[\"prob\"]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.apply_along_axis(self._predict_one, 1, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "da23901c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 4)"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded = load_iris()\n",
    "data, target = loaded[\"data\"], loaded[\"target\"]\n",
    "X_tr, X_tst, y_tr, y_tst = train_test_split(data, target, test_size=0.4)\n",
    "\n",
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "724565cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leaf': False,\n",
      " 'lt': {'leaf': True, 'prob': array([1., 0., 0.]), 'size': 34},\n",
      " 'rt': {'leaf': False,\n",
      "        'lt': {'leaf': False,\n",
      "               'lt': {'leaf': True, 'prob': array([0., 1., 0.]), 'size': 25},\n",
      "               'rt': {'leaf': True,\n",
      "                      'prob': array([0.        , 0.33333333, 0.66666667]),\n",
      "                      'size': 3},\n",
      "               'size': 28,\n",
      "               'split': (3, 1.65)},\n",
      "        'rt': {'leaf': False,\n",
      "               'lt': {'leaf': True,\n",
      "                      'prob': array([0.        , 0.33333333, 0.66666667]),\n",
      "                      'size': 3},\n",
      "               'rt': {'leaf': True, 'prob': array([0., 0., 1.]), 'size': 25},\n",
      "               'size': 28,\n",
      "               'split': (3, 1.7000000000000002)},\n",
      "        'size': 56,\n",
      "        'split': (2, 4.85)},\n",
      " 'size': 90,\n",
      " 'split': (2, 2.45)}\n"
     ]
    }
   ],
   "source": [
    "tree = DT(max_depth=3)\n",
    "tree.fit(X_tr, y_tr)\n",
    "pprint(tree.tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "d23db358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = tree.predict(X_tst)\n",
    "y_pred = np.argmax(y_prob, 1)\n",
    "(y_pred == y_tst).sum() / len(y_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "99497fad-168d-40e9-a683-01b9a9393c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9385964912280702"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded = load_breast_cancer()\n",
    "data, target = loaded[\"data\"], loaded[\"target\"]\n",
    "X_tr, X_tst, y_tr, y_tst = train_test_split(data, target, test_size=0.4)\n",
    "\n",
    "tree = DT(max_depth=3)\n",
    "tree.fit(X_tr, y_tr)\n",
    "\n",
    "y_prob = tree.predict(X_tst)\n",
    "y_pred = np.argmax(y_prob, 1)\n",
    "(y_pred == y_tst).sum() / len(y_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b928c4",
   "metadata": {},
   "source": [
    "본문에서는 Adaboost or Adaptive Boosting 을 구현한다. Adaboost 는 다음과 같이 작동한다.\n",
    "\n",
    "다음 시행을 반복한다.\n",
    "1. weak learner 로 depth 가 1인 DT, 즉 stump 를 사용한다. 이 모델을 $M_{i-1}$ 이라 하자. 초기 샘플 가중치 $w_0$는 모든 샘플에 대해 같다. 즉 $w_0=1/n$. 따라서 $i=0$일 경우 $M_0$을 원래 데이터 $\\{(x,y)\\}_0$에 적합시킨다.\n",
    "2. Amount of Say 를 구한다. $$ AOS = \\frac{1}{2}\\log(\\frac{1-Total Error}{Total Error}) $$\n",
    "3. 샘플 가중치를 다음과 같이 업데이트 한다.\n",
    "    1. 모델이 정답을 맞춘 샘플일 경우 $w_i = w_{i-1} * e^{-AOS}$\n",
    "    2. 그렇지 않을 경우 $w_i = w_{i-1} * e^{AOS}$\n",
    "4. 새로운 샘플 가중치에 따라 샘플링 하여 새로운 데이터 $\\{(x,y)\\}_i$ 를 만든다.\n",
    "\n",
    "위 시행을 반복하면 여러개의 weak learner 와 그에 해당하는 Amount Of Say 가 나온다. 예측 할 때 각 Amount Of Say 를 가중치로 두어 확률을 구하고 가장 큰 항목을 정답으로 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "9c75b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    def __init__(self, n_estimators=10):\n",
    "        self.learners = []\n",
    "        self.n_estimators = n_estimators\n",
    "    \n",
    "    def _aos(self, stump):\n",
    "        err = 0\n",
    "        if stump[\"leaf\"] == False:\n",
    "            lt, rt = stump[\"lt\"], stump[\"rt\"]\n",
    "            err = 1 - (np.max(lt[\"prob\"]) * lt[\"size\"] + np.max(rt[\"prob\"]) * rt[\"size\"]) / stump[\"size\"]\n",
    "        return np.log((1-err+1e-15)/(err+1e-15))/2\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        w = np.ones_like(y) / len(y)\n",
    "        self.learners.append(DT(max_depth=1, weights=w))\n",
    "        self.aos = []\n",
    "        data = X\n",
    "        label = y\n",
    "        \n",
    "        for learner in self.learners:\n",
    "            # Step 1\n",
    "            learner.fit(data, label)\n",
    "            \n",
    "            # Step 2\n",
    "            aos = self._aos(learner.tree)\n",
    "            self.aos.append(aos)\n",
    "            if len(self.aos) == self.n_estimators:\n",
    "                break\n",
    "                \n",
    "            # Step 3\n",
    "            prob = learner.predict(data)\n",
    "            w[np.where(np.argmax(prob, axis=1) == label)] *= np.exp(-aos)\n",
    "            w[np.where(np.argmax(prob, axis=1) != label)] *= np.exp(aos)\n",
    "            w = w / np.sum(w)\n",
    "            \n",
    "            # Step 4 (DT 자체에 샘플 가중치를 적용 시키는 것이 더 좋으므로 생략)\n",
    "            #idx = np.random.choice(len(label), len(label), replace=True, p=w)\n",
    "            #data = X[idx, :]\n",
    "            #label = y[idx]\n",
    "            self.learners.append(DT(max_depth=1, weights=w))\n",
    "        self.aos = np.array(self.aos)\n",
    "            \n",
    "    def _predict_one(self, x):\n",
    "        probs = np.array([learner._predict_one(x) for learner in self.learners])\n",
    "        w = self.aos / np.sum(self.aos)\n",
    "        return w.dot(probs)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.apply_along_axis(self._predict_one, 1, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "6207ed46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 4)"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded = load_iris()\n",
    "data, target = loaded[\"data\"], loaded[\"target\"]\n",
    "X_tr, X_tst, y_tr, y_tst = train_test_split(data, target, test_size=0.4)\n",
    "\n",
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "0c32b619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39746494, 0.4252533 , 0.47291081, 0.38910173, 0.69000059,\n",
       "       0.46212709, 0.58721052, 0.64257156, 0.50355015, 0.4692775 ])"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost = AdaBoost()\n",
    "boost.fit(X_tr, y_tr)\n",
    "boost.aos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "b7ddacc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = boost.predict(X_tst)\n",
    "y_pred = np.argmax(y_prob, 1)\n",
    "(y_pred == y_tst).sum() / len(y_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "9af9f9d4-2b44-4757-a722-94daeb03008b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded = load_breast_cancer()\n",
    "data, target = loaded[\"data\"], loaded[\"target\"]\n",
    "X_tr, X_tst, y_tr, y_tst = train_test_split(data, target, test_size=0.4)\n",
    "\n",
    "boost = AdaBoost()\n",
    "boost.fit(X_tr, y_tr)\n",
    "boost.aos\n",
    "\n",
    "y_prob = boost.predict(X_tst)\n",
    "y_pred = np.argmax(y_prob, 1)\n",
    "(y_pred == y_tst).sum() / len(y_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8163825-e8a6-44a3-b8cc-14d1a7bf9721",
   "metadata": {},
   "source": [
    "타이타닉 데이터에 대해서 DT 와 AdaBoost 를 적용시켜 다음을 비교해보자.\n",
    "1. 직접 구현한 DT\n",
    "2. sklearn의 DT\n",
    "2. 직접 구현한 AdaBoost\n",
    "3. sklearn의 AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "4749c23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Pclass_0</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Sex_0</th>\n",
       "      <th>Sex_1</th>\n",
       "      <th>Embarked_0</th>\n",
       "      <th>Embarked_1</th>\n",
       "      <th>Embarked_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.592148</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.502163</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638430</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.786404</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.284503</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.488580</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407697</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420494</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407697</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.486064</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex       Age  SibSp  Parch      Fare  Embarked  \\\n",
       "0         0       2    0 -0.592148      1      0 -0.502163         2   \n",
       "1         1       0    1  0.638430      1      0  0.786404         0   \n",
       "2         1       2    1 -0.284503      0      0 -0.488580         2   \n",
       "3         1       0    1  0.407697      1      0  0.420494         2   \n",
       "4         0       2    0  0.407697      0      0 -0.486064         2   \n",
       "\n",
       "   Pclass_0  Pclass_1  Pclass_2  Sex_0  Sex_1  Embarked_0  Embarked_1  \\\n",
       "0       0.0       0.0       1.0    1.0    0.0         0.0         0.0   \n",
       "1       1.0       0.0       0.0    0.0    1.0         1.0         0.0   \n",
       "2       0.0       0.0       1.0    0.0    1.0         0.0         0.0   \n",
       "3       1.0       0.0       0.0    0.0    1.0         0.0         0.0   \n",
       "4       0.0       0.0       1.0    1.0    0.0         0.0         0.0   \n",
       "\n",
       "   Embarked_2  \n",
       "0         1.0  \n",
       "1         0.0  \n",
       "2         1.0  \n",
       "3         1.0  \n",
       "4         1.0  "
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 편의상 이미 전처리 되어있는 titanic 데이터를 이용한다.\n",
    "tr = pd.read_csv(\"data/titanic_tr.csv\")\n",
    "tst = pd.read_csv(\"data/titanic_tst.csv\")\n",
    "tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "d8166066-3099-4189-b773-ab9879970af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 15)"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(tr.drop([\"Survived\"], axis=1))\n",
    "target = np.array(tr[\"Survived\"])\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "000f7127-08fb-431d-b50e-6d7781fd25ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(623, 15)"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr, X_tst, y_tr, y_tst = train_test_split(data, target, test_size=0.3)\n",
    "\n",
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "d251b80d-02dd-48fc-9d12-b652442d8e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8134328358208955"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 직접 구현 한 DT\n",
    "tree = DT(max_depth=3)\n",
    "tree.fit(X_tr, y_tr)\n",
    "\n",
    "y_prob = tree.predict(X_tst)\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "(y_pred == y_tst).sum() / len(y_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "8b782fd0-8c59-4f4f-8e36-03ef65712fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7985074626865671"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn 의 DT\n",
    "treemodel = DecisionTreeClassifier()\n",
    "treemodel.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = treemodel.predict(X_tst)\n",
    "(y_pred == y_tst).sum() / len(y_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "382a5d81-46b9-443d-8cb6-b8652a17ac52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7649253731343284"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 직접 구현한 AdaBoost\n",
    "boost = AdaBoost()\n",
    "boost.fit(X_tr, y_tr)\n",
    "\n",
    "y_prob = boost.predict(X_tst)\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "(y_pred == y_tst).sum() / len(y_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "59dfa1b4-c83f-467f-bb68-92b86782b084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8134328358208955"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn 의 AdaBoost\n",
    "boostmodel = AdaBoostClassifier()\n",
    "boostmodel.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = boostmodel.predict(X_tst)\n",
    "(y_pred == y_tst).sum() / len(y_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8811d7d-4581-47f7-8a26-077535eeb84f",
   "metadata": {},
   "source": [
    "Boosting 은 weak learner 가 풀지 못하는 문제, 즉 어려운 문제에 집중하기 때문에 데이터가 복잡할 수록 더 좋은 성능을 낸다. 하지만 위 데이터는 복잡하지 않은 데이터라서 DT 와 큰 성능차이를 보이지 않는다.\n",
    "\n",
    "sklearn의 모델은 여러 최적화가 들어가 있어 속도와 예측력 측면에서 직접 구현한 코드보다 더 좋은 성능을 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf600a3d-1385-4757-8967-15671af52551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
